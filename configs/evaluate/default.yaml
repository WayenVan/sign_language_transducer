hydra:
  run: 
    dir: outputs/${hydra.job.name}/${now:%Y-%m-%d_%H-%M-%S}/${hydra.job.name}_${description}

description: MyModel

csi: csi_sign_language
transform: torchvision.transforms
T: torchvision.transforms
CT: csi_sign_language.data.transforms

checkpoint_dir: outputs/train/2024-02-07_13-49-54/train_TadaWithTransformer
train_config: ${checkpoint_dir}/.hydra/config.yaml
checkpoint: ${checkpoint_dir}/checkpoint.pt
phoenix14_root: /home/jingyan/Documents/sign_language_rgb/preprocessed/ph14_lmdb
evaluation_tool: /home/jingyan/Documents/sign_language_rgb/evaluation/ph14

device: cuda

inferencer:
  _target_: ${csi}.engines.inferencer.Inferencer
  device: ${device}

data:
  subset: multisigner
  collate_fn: 
    _target_: ${csi}.data.dataset.phoenix14.CollateFn
  video_transform: 
        _target_: ${T}.Compose
        transforms: 
        - _target_: ${CT}.video.ToTensor
          keys: [video, gloss]
        - _target_: ${CT}.video.FrameScale
          min: -1.
          max: 1.
        - _target_: ${CT}.video.CentralCrop
          size: 224
  test_set: 
    _target_: ${csi}.data.dataset.phoenix14.MyPhoenix14Dataset
    data_root: ${phoenix14_root}
    subset: ${data.subset}
    mode: test
    transform: ${data.video_transform}
  test_loader:
    _target_: torch.utils.data.DataLoader
    batch_size: 2
    num_workers: 12
    dataset: ${data.test_set}
    collate_fn: ${data.collate_fn}
