hydra:
  run: 
    dir: outputs/${hydra.job.name}/${now:%Y-%m-%d_%H-%M-%S}/${hydra.job.name}_${description}
  
description: transformer

csi: csi_sign_language
transform: torchvision.transforms
T: torchvision.transforms
CT: csi_sign_language.data.transforms

seed: 3407
phoenix14_root: preprocessed/ph14_lmdb
device: cuda
epoch: 80
#-1 when we don want message out
message_interval: 50
non_block: False
pin_memory: False
num_workers: 4

#if continuos read model
load_weights: False
is_resume: False
checkpoint: /home/jingyan/Documents/sign_language_rgb/outputs/staged/2024-01-28_15-06-00/train_transformer/checkpoint.pt

model:
  _target_: ${csi}.models.model.SLRModel
  backbone: 
    _target_: ${csi}.models.backbones.backbone.ResnetTransformer
    d_feedforward: 1024
    n_head: 8
    n_class: 1296
    layers: 2
  loss_temp: 8
  loss_weight: [1.0, 1., 25.]

optimizer:
  _target_: torch.optim.Adam
  lr: 1e-4
  weight_decay: 0.0001

lr_scheduler:
  _target_: torch.optim.lr_scheduler.StepLR
  step_size: 20
  gamma: 0.2

trainner:
  _target_: ${csi}.engines.trainner.Trainner
  device: ${device}
  message_interval: ${message_interval}

inferencer:
  _target_: ${csi}.engines.inferencer.Inferencer
  device: ${device}

data:
  subset: multisigner
  collate_fn: 
    _target_: ${csi}.data.dataset.phoenix14.CollateFn
  video_transform: 
        _target_: ${T}.Compose
        transforms: 
        - _target_: ${CT}.video.RandomCrop
          size: 224
        - _target_: ${CT}.video.RandomHorizontalFlip
          prob: 0.5
        - _target_: ${CT}.video.TemporalRescale
          temp_scaling: 0.2
        - _target_: ${CT}.video.FrameScale
          min: -1.
          max: 1.
        - _target_: ${CT}.video.ToTensor
          keys: [video, gloss]
    
  train_set: 
    _target_: ${csi}.data.dataset.phoenix14.MyPhoenix14Dataset
    data_root: ${phoenix14_root}
    subset: ${data.subset}
    mode: train
    transform: ${data.video_transform}

  val_set: 
    _target_: ${csi}.data.dataset.phoenix14.MyPhoenix14Dataset
    data_root: ${phoenix14_root}
    subset: ${data.subset}
    mode: dev
    transform: ${data.video_transform}


  train_loader:
    _target_: torch.utils.data.DataLoader
    batch_size: 1
    num_workers: ${num_workers}
    pin_memory: ${pin_memory}
    shuffle: True
    dataset: ${data.train_set}
    collate_fn: ${data.collate_fn}

  val_loader:
    _target_: torch.utils.data.DataLoader
    batch_size: 2
    num_workers: ${num_workers}
    pin_memory: ${pin_memory}
    dataset: ${data.val_set}
    collate_fn: ${data.collate_fn}


