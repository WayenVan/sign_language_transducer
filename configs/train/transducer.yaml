hydra:
  run: 
    dir: outputs/${hydra.job.name}/${now:%Y-%m-%d_%H-%M-%S}/${hydra.job.name}_${description}
  
description: x3d_with_LSTM

csi: csi_sign_language
transform: torchvision.transforms
T: torchvision.transforms
CT: csi_sign_language.data.transforms

phoenix14_root: preprocessed/ph14_lmdb

seed: 3407
device: cuda
epoch: 80
#-1 when we don want message out
message_interval: 1
non_block: False
pin_memory: False
num_workers: 5
batch_size: 2
vocab_size: 1296

#if continuos read model
load_weights: False
is_resume: False
checkpoint: /home/jingyan/Documents/sign_language_rgb/outputs/train/2024-02-15_02-49-55/train_x3d_with_LSTM/checkpoint.pt

model:
  _target_: csi_sign_language.models.model_rna.SLRTransducer
  encoder: 
    _target_: ${csi}.modules.video_encoders.x3dbased.X3dLSTM
    d_model: 1024
    n_layers: 2
    dropout: 0.5
  predictor: 
    _target_: ${csi}.modules.predictor.BasePredictor
    d_model: 1024
    output_size: 1024
    vocab_size: ${vocab_size}
    n_layers: 2
    dropout: 0.2
  joint_net:
    _target_: ${csi}.modules.jointnet.JointNet
    d_model: 1024
    enc_dim: 1024
    pred_dim: 1024
    vocab_size: ${vocab_size}

optimizer:
  _target_: torch.optim.Adam
  lr: 3e-5
  weight_decay: 0.0001

lr_scheduler:
  _target_: torch.optim.lr_scheduler.StepLR
  step_size: 30
  gamma: 0.5

trainner:
  _target_: ${csi}.engines.trainner.Trainner
  device: ${device}
  message_interval: ${message_interval}

inferencer:
  _target_: ${csi}.engines.inferencer.Inferencer
  device: ${device}

data:
  excluded: ["13April_2011_Wednesday_tagesschau_default-14",]
  subset: multisigner
  collate_fn: 
    _target_: ${csi}.data.dataset.phoenix14.CollateFn
  video_transform: 
        _target_: ${T}.Compose
        transforms: 
        - _target_: ${CT}.video.RandomCrop
          size: 224
        - _target_: ${CT}.video.RandomHorizontalFlip
          prob: 0.5
        - _target_: ${CT}.video.Resize
          h: 160
          w: 160
        - _target_: ${CT}.video.TemporalRescale
          temp_scaling: 0.2
        - _target_: ${CT}.video.FrameScale
          min: -1.
          max: 1.
        - _target_: ${CT}.video.ToTensor
          keys: [video, gloss]
    
  train_set: 
    _target_: ${csi}.data.dataset.phoenix14.MyPhoenix14Dataset
    data_root: ${phoenix14_root}
    subset: ${data.subset}
    mode: train
    transform: ${data.video_transform}

  val_set: 
    _target_: ${csi}.data.dataset.phoenix14.MyPhoenix14Dataset
    data_root: ${phoenix14_root}
    subset: ${data.subset}
    mode: dev
    transform: ${data.video_transform}


  train_loader:
    _target_: torch.utils.data.DataLoader
    batch_size: ${batch_size}
    num_workers: ${num_workers}
    pin_memory: ${pin_memory}
    shuffle: true
    dataset: ${data.train_set}
    collate_fn: ${data.collate_fn}

  val_loader:
    _target_: torch.utils.data.DataLoader
    batch_size: ${batch_size}
    num_workers: ${num_workers}
    pin_memory: ${pin_memory}
    dataset: ${data.val_set}
    collate_fn: ${data.collate_fn}
